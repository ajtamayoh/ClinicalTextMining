{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>mark</th>\n",
       "      <th>label</th>\n",
       "      <th>off0</th>\n",
       "      <th>off1</th>\n",
       "      <th>span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32032497_ES</td>\n",
       "      <td>T1</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>112</td>\n",
       "      <td>118</td>\n",
       "      <td>hombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32032497_ES</td>\n",
       "      <td>T2</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>1025</td>\n",
       "      <td>1033</td>\n",
       "      <td>paciente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32032497_ES</td>\n",
       "      <td>T3</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>1098</td>\n",
       "      <td>1106</td>\n",
       "      <td>paciente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32032497_ES</td>\n",
       "      <td>T4</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>1395</td>\n",
       "      <td>1403</td>\n",
       "      <td>paciente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32032497_ES</td>\n",
       "      <td>T5</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>1075</td>\n",
       "      <td>1084</td>\n",
       "      <td>2019-nCoV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16092</th>\n",
       "      <td>es-S1699-695X2017000100011-1</td>\n",
       "      <td>T14</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>1585</td>\n",
       "      <td>1593</td>\n",
       "      <td>hermanas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16093</th>\n",
       "      <td>es-S1699-695X2017000100011-1</td>\n",
       "      <td>T15</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>1679</td>\n",
       "      <td>1686</td>\n",
       "      <td>familia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16094</th>\n",
       "      <td>es-S1699-695X2017000100011-1</td>\n",
       "      <td>T16</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>1721</td>\n",
       "      <td>1729</td>\n",
       "      <td>hermanas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16095</th>\n",
       "      <td>es-S1699-695X2017000100011-1</td>\n",
       "      <td>T17</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>1735</td>\n",
       "      <td>1742</td>\n",
       "      <td>hermano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16096</th>\n",
       "      <td>es-S1699-695X2017000100011-1</td>\n",
       "      <td>T18</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>1448</td>\n",
       "      <td>1464</td>\n",
       "      <td>familiar materna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16097 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename mark    label  off0  off1  \\\n",
       "0                       32032497_ES   T1    HUMAN   112   118   \n",
       "1                       32032497_ES   T2    HUMAN  1025  1033   \n",
       "2                       32032497_ES   T3    HUMAN  1098  1106   \n",
       "3                       32032497_ES   T4    HUMAN  1395  1403   \n",
       "4                       32032497_ES   T5  SPECIES  1075  1084   \n",
       "...                             ...  ...      ...   ...   ...   \n",
       "16092  es-S1699-695X2017000100011-1  T14    HUMAN  1585  1593   \n",
       "16093  es-S1699-695X2017000100011-1  T15    HUMAN  1679  1686   \n",
       "16094  es-S1699-695X2017000100011-1  T16    HUMAN  1721  1729   \n",
       "16095  es-S1699-695X2017000100011-1  T17    HUMAN  1735  1742   \n",
       "16096  es-S1699-695X2017000100011-1  T18    HUMAN  1448  1464   \n",
       "\n",
       "                   span  \n",
       "0                hombre  \n",
       "1              paciente  \n",
       "2              paciente  \n",
       "3              paciente  \n",
       "4             2019-nCoV  \n",
       "...                 ...  \n",
       "16092          hermanas  \n",
       "16093           familia  \n",
       "16094          hermanas  \n",
       "16095           hermano  \n",
       "16096  familiar materna  \n",
       "\n",
       "[16097 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_spe = pd.read_csv(\"training_entities_subtask1.tsv\", delimiter=\"\\t\")\n",
    "data_spe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_out = open(\"LivingNER_training.json\", 'w', encoding=\"UTF-8\")\n",
    "f_out.write('{\"version\": \"0.1.0\",\\n\"data\": [')\n",
    "test_path = \"text_files\"\n",
    "test_files = os.listdir(test_path)\n",
    "for f in test_files:\n",
    "    with open(test_path+'/'+f, \"r\", encoding=\"UTF-8\") as ftest:\n",
    "        texto = ftest.read()\n",
    "    fl = data_dis[data_spe['filename'] == f[:-4]].sort_values('off0', ascending=True)\n",
    "    species = []\n",
    "    species_lb = []\n",
    "    for i in range(len(fl)):\n",
    "        species.append(fl['span'].iloc[i])\n",
    "        species_lb.append(fl['label'].iloc[i])\n",
    "    for p, l in zip(species, species_lb):        \n",
    "        tagged = [a+\"___I#-#D#I#S#E#A#S#E\" for a in p.split()]\n",
    "        tagged[0] = tagged[0].replace('I#-#D#I#S#E#A#S#E', 'B#-#D#I#S#E#A#S#E')\n",
    "        txt_tag = ' '.join( tagged )\n",
    "        #texto = re.sub(texto[start:end],txt_tag,texto)\n",
    "        texto = texto.replace(p, txt_tag)\n",
    "        texto = texto.replace('. ',' . ')\n",
    "        texto = texto.replace('.\\n',' . ')\n",
    "        texto = texto.replace(', ',' , ')\n",
    "        texto = texto.replace(': ',' : ')\n",
    "        texto = texto.replace('! ',' ! ')\n",
    "        texto = texto.replace('? ',' ? ')\n",
    "        texto = texto.replace('; ',' ; ')\n",
    "        texto = texto.replace(') ',' ) ')\n",
    "        texto = texto.replace('\" ',' \\\" ')\n",
    "        texto = texto.replace(' (',' ( ')\n",
    "        texto = texto.replace(' \"',' \\\" ')\n",
    "        texto = texto.replace('  ', ' ')\n",
    "    texto = texto.split()\n",
    "    ner_tags = []\n",
    "    tokens = []\n",
    "    for w in texto:\n",
    "        #if w.endswith('B-DISEASE') or w.endswith('I-DISEASE'):\n",
    "            #wp = w.split('___')\n",
    "            #tokens.append(wp[0])\n",
    "            #ner_tags.append(wp[1])\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        #validate double tags\n",
    "        if \"___B#-#D#I#S#E#A#S#E___B#-#D#I#S#E#A#S#E\" in w:\n",
    "            #print(w)\n",
    "            w = w.replace(\"___B#-#D#I#S#E#A#S#E___B#-#D#I#S#E#A#S#E\",\"___B#-#D#I#S#E#A#S#E\")\n",
    "        elif \"___B#-#D#I#S#E#A#S#E___I#-#D#I#S#E#A#S#E\" in w:\n",
    "            #print(w)\n",
    "            w = w.replace(\"___B#-#D#I#S#E#A#S#E___I#-#D#I#S#E#A#S#E\",\"___I#-#D#I#S#E#A#S#E\")\n",
    "        elif \"___I#-#D#I#S#E#A#S#E___B#-#D#I#S#E#A#S#E\" in w:\n",
    "            #print(w)\n",
    "            w = w.replace(\"___I#-#D#I#S#E#A#S#E___B#-#D#I#S#E#A#S#E\",\"___B#-#D#I#S#E#A#S#E\")\n",
    "        elif \"___I#-#D#I#S#E#A#S#E___I#-#D#I#S#E#A#S#E\" in w:\n",
    "            #print(w)\n",
    "            w = w.replace(\"___I#-#D#I#S#E#A#S#E___I#-#D#I#S#E#A#S#E\",\"___I#-#D#I#S#E#A#S#E\")\n",
    "        '''\n",
    "        \n",
    "        if \"B#-#D#I#S#E#A#S#E\" in w:\n",
    "            wp = w.replace(\"___B#-#D#I#S#E#A#S#E\", \"\")\n",
    "            wp = wp.replace(\"___I#-#D#I#S#E#A#S#E\", \"\") #To clean multiple tags\n",
    "            tokens.append(wp)\n",
    "            ner_tags.append(\"B-DISEASE\")\n",
    "        elif \"I#-#D#I#S#E#A#S#E\" in w:\n",
    "            wp = w.replace(\"___I#-#D#I#S#E#A#S#E\", \"\")\n",
    "            tokens.append(wp)\n",
    "            ner_tags.append(\"I-DISEASE\")\n",
    "        else:\n",
    "            tokens.append(w)\n",
    "            ner_tags.append(\"O\")\n",
    "        if w == \".\":\n",
    "            dicc = {\"ner_tags\": ner_tags, \"tokens\": tokens}\n",
    "            f_out.write(str(dicc)+',\\n')\n",
    "            ner_tags = []\n",
    "            tokens = []\n",
    "    #print(tokens, len(tokens))\n",
    "    #print(ner_tags, len(ner_tags))\n",
    "f_out.write(\"]}\")\n",
    "f_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
