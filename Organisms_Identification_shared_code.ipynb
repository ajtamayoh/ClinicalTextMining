{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajtamayoh/ClinicalTextMining/blob/main/Organisms_Identification_shared_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clinical Text Mining in Spanish (Organisms)\n",
        "\n",
        "Here you are the source code for the paper:\n",
        "\n",
        "### Clinical Text Mining in Spanish Enhanced by Negation Detection and Named Entity Recognition\n",
        "\n",
        "Authors:\n",
        "\n",
        "Antonio Tamayo (ajtamayo2019@ipn.cic.mx, ajtamayoh@gmail.com)\n",
        "\n",
        "Diego A. Burgos (burgosda@wfu.edu)\n",
        "\n",
        "Alexander Gelbulkh (gelbukh@gelbukh.com)\n",
        "\n",
        "For bugs or questions related to the code, do not hesitate to contact us (Antonio Tamayo: ajtamayoh@gmail.com)\n",
        "\n",
        "If you use this code please cite our work:\n",
        "\n",
        "Comming soon ...\n",
        "\n"
      ],
      "metadata": {
        "id": "Nml9hXt1NHXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements\n",
        "\n",
        "To run this code you need to download the dataset (three files: LivingNER_training.json, LivingNER_validations.json and LivingNER_testing.json) at: [download dataset](https://github.com/ajtamayoh/ClinicalTextMining/tree/main/Organisms/Dataset)\n",
        "\n",
        "Then, you must create a folder called \"Datasets\" in the root of your Google Drive and load there both folders previously downloaded.\n",
        "\n",
        "Once the dataset is ready to use, you should [open this notebook in colab](https://colab.research.google.com/github/ajtamayoh/ClinicalTextMining/blob/main/Organisms_Identification_shared_code.ipynb) and save a copy in your drive."
      ],
      "metadata": {
        "id": "6S9L_KErP3yM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About the infrastructure"
      ],
      "metadata": {
        "id": "3gGu8XvkQuHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "9YCD8Yn8QvCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "PDijHzOMQzwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WaBFjAEUc0l"
      },
      "source": [
        "## Install the Transformers and Datasets libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEX7xfLiUc0m"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "# To run the training on TPU, you will need to uncomment the followin line:\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!apt install git-lfs\n",
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face Authentication\n",
        "\n",
        "If you want to save your own model and make it available online we strongly recommend signing up at: https://huggingface.co/"
      ],
      "metadata": {
        "id": "K90ROU-SaLC5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgxCB7y8Uc0n"
      },
      "source": [
        "You will need to setup git, adapt your email and name in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hstit1gRUc0o"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"your_email\"\n",
        "!git config --global user.name \"your_name\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXbs9i1fUc0o"
      },
      "source": [
        "You will also need to be logged in to the Hugging Face Hub. Execute the following and enter your credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6SkGUEUUc0p"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting to Google drive"
      ],
      "metadata": {
        "id": "U64pk_flQ-nw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgzIfAnfaDR1",
        "outputId": "aace3046-8a51-44fd-bff9-bf2fca69e213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1ncKARiLoRQ"
      },
      "source": [
        "## Exploring & Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZaPi7EMLrz8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RIR3iRCUc0h"
      },
      "source": [
        "# Organisms identification as a Token classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9FTB991Sl12"
      },
      "source": [
        "## Loading the Preprocessed Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import json\n",
        "\n",
        "# LivingNER dataset (preprocessed 4 BIO)\n",
        "LivingNER_dataset_train = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/Datasets/LivingNER_training.json\", field=\"data\")\n",
        "LivingNER_dataset_val = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/Datasets/LivingNER_validation.json\", field=\"data\")\n",
        "LivingNER_dataset_test = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/Datasets/LivingNER_testing.json\", field=\"data\")"
      ],
      "metadata": {
        "id": "1R8ozApsxGSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMZbF0mSaOiS"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# Training, validation, and Testing partitions from LivingNER\n",
        "raw_datasets = DatasetDict({\n",
        "    'train': LivingNER_dataset_train['train'],\n",
        "    'validation': LivingNER_dataset_val['train'],\n",
        "    'test': LivingNER_dataset_test['train']\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFQfd5u9Uc0q",
        "outputId": "320fc58d-9663-44fe-86eb-e6150139f2e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['ner_tags', 'tokens'],\n",
              "        num_rows: 27810\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['ner_tags', 'tokens'],\n",
              "        num_rows: 12480\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['ner_tags', 'tokens'],\n",
              "        num_rows: 12955\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-usgjZalK7E9",
        "outputId": "9a4922df-925f-46c0-f544-a59a9b908a68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['ner_tags', 'tokens'],\n",
              "    num_rows: 20857\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "raw_datasets['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLHqEaOVUc0u",
        "outputId": "214cce48-cc40-4e58-fa0f-9c2a4a09163b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'HUMAN', 'SPECIES']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "label_names = ['O','HUMAN','SPECIES']\n",
        "label_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iCYOiwZUc0u",
        "outputId": "0fe4a1ba-fe33-4655-f366-a46683d90852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El 1 de enero de 2020 , ingresó en el Union Hospital ( facultad de medicina Tongji , Wuhan , provincia de Hubei ) un hombre de 42 años con hipertermia ( 39,6 °C ) , tos y que refería fatiga de una semana de evolución . \n",
            "O  O O  O     O  O    O O       O  O  O     O        O O        O  O        O      O O     O O         O  O     O O  HUMAN  O  O  O    O   O           O O    O  O O O   O O   O       O      O  O   O      O  O         O \n"
          ]
        }
      ],
      "source": [
        "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
        "labels = [int(n) for n in raw_datasets[\"train\"][0][\"ner_tags\"]]\n",
        "#labels = raw_datasets[\"train\"][0][\"pos_tags\"]\n",
        "#labels = raw_datasets[\"train\"][0][\"chunk_tags\"]\n",
        "line1 = \"\"\n",
        "line2 = \"\"\n",
        "for word, label in zip(words, labels):\n",
        "    full_label = label_names[label]\n",
        "    max_length = max(len(word), len(full_label))\n",
        "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "print(line1)\n",
        "print(line2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading mBERT as a pre-trained model"
      ],
      "metadata": {
        "id": "CRKUqAVVbvf7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuZTRxLPUc0v"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"bert-base-multilingual-cased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr7qjUe7Uc0v",
        "outputId": "0d9b7b33-ab29-44bd-bc9e-27e431c298bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbchCgPGUc0v"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
        "inputs.tokens()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udiVaGenUc0w"
      },
      "outputs": [],
      "source": [
        "inputs.word_ids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhu4Cl3-Uc0w"
      },
      "outputs": [],
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Start of a new word!\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Special token\n",
        "            new_labels.append(-100)\n",
        "        else:\n",
        "            # Same word as previous token\n",
        "            label = labels[word_id]\n",
        "            # If the label is B-XXX we change it to I-XXX\n",
        "            if label % 2 == 1:\n",
        "                label += 1\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H820wg0sUc0x"
      },
      "outputs": [],
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "word_ids = inputs.word_ids()\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-ZxnhGSUc0x"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
        "    )\n",
        "    all_labels = examples[\"ner_tags\"]\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INNjCms4Uc0y"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFpUXjvmUc0y"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHCuXD5EUc0y"
      },
      "outputs": [],
      "source": [
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
        "batch[\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6GW37IPUc0z"
      },
      "outputs": [],
      "source": [
        "for i in range(2):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDjn2La4Uc0z"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mqjInn4Uc0z"
      },
      "outputs": [],
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "labels = [label_names[i] for i in labels]\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIaLt4n-Uc00"
      },
      "outputs": [],
      "source": [
        "predictions = labels.copy()\n",
        "predictions[2] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xewJhf6Uc00"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdmwR_2HUc00"
      },
      "outputs": [],
      "source": [
        "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svP0J1bWs3pK",
        "outputId": "e5eac53a-af65-48cd-b489-95cdadd0caa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 'O', '1': 'HUMAN', '2': 'SPECIES'}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvIvq5wxs8P8",
        "outputId": "55663a3d-2999-4aaa-ae5d-4133aabbc127"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': '0', 'HUMAN': '1', 'SPECIES': '2'}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "label2id"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing the head of prediction for Organism Mentions Identification under the BIO scheme"
      ],
      "metadata": {
        "id": "FKNvor68cVQs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "a7a1206483c943629eb275efad778604",
            "bcceebadf1a84506851de9be3bb5f445",
            "240505ccac0b4df195714a05c8cbf76e",
            "aedbd116a0c440dcaad1b27538bee22d",
            "03390e8efc104ce1bb02369466aa5432",
            "2308e9e1f5224b24bd474d09d51cabb2",
            "8f546f8e42d54b688bc2fe0f1878a94d",
            "068447f162754e13b1158e18f97b2f0d",
            "91956b73060b48c6a95513373d7eac15",
            "cb52128e47694a8eab6fb71b8dd8ac5d",
            "1b65950e82f841bca67f66cf15f9247f"
          ]
        },
        "id": "z9Rrve75Uc00",
        "outputId": "2234ad97-af63-4ee2-c0b4-cbc29a396b03"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7a1206483c943629eb275efad778604"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(    \n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    num_labels = 3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDiAYqsYUc00",
        "outputId": "6da2628b-ee23-4b26-ed77-d96ae98cf01d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model.config.num_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS-L0U1XUc01"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \n",
        "    \"Species_Identification_mBERT_fine_tuned_Train_Test_your_identifier\",\n",
        "    \n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.1,\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning Transformer-based model for Procedure mentions identification"
      ],
      "metadata": {
        "id": "tdHv4CMvctoB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvHls_JJUc01"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    #eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the fine-tuned model at Hugging Face (It requires previous authentication)"
      ],
      "metadata": {
        "id": "0rGdJ42qc3sh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAvTQZClUc01"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(commit_message=\"Training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjEM4d77Toxs"
      },
      "source": [
        "## Loading the model for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKO5fyKyUc04"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_checkpoint = \"ajtamayoh/Species_Identification_mBERT_fine_tuned_Train_Test_your_identifier\"\n",
        "\n",
        "token_classifier = pipeline(\n",
        "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr7QlXqoaaMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dca1cdc-9626-43dc-c440-8f551dc45fc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'HUMAN',\n",
              "  'score': 0.9996307,\n",
              "  'word': 'Pac',\n",
              "  'start': 3,\n",
              "  'end': 6},\n",
              " {'entity_group': 'SPECIES',\n",
              "  'score': 0.99972814,\n",
              "  'word': '##iente',\n",
              "  'start': 6,\n",
              "  'end': 11}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "pred = token_classifier(\"El Paciente hipertenso no presenta fiebre ni infección.\")\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL4mdo1umfTJ"
      },
      "outputs": [],
      "source": [
        "test_path = \"Path_to_test_files\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-Processing"
      ],
      "metadata": {
        "id": "5SXdOl-E6Qk6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blQLws4pLuBP"
      },
      "outputs": [],
      "source": [
        "def grouping_entities(pred):\n",
        "  import re\n",
        "  output = []\n",
        "  for e in pred:\n",
        "    #for RoBERTa\n",
        "    if e['word'].startswith(' '):\n",
        "      e['word'] = e['word'][1:]\n",
        "    ###\n",
        "\n",
        "    if \"##\" not in e['word']:\n",
        "      output.append(e)\n",
        "    else:\n",
        "      try:\n",
        "        if e['start'] == (output[-1]['end']):\n",
        "          output[-1]['word'] = output[-1]['word']+re.sub(\"##\",\"\",e['word'])\n",
        "          output[-1]['end'] = e['end']\n",
        "      except:\n",
        "        pass\n",
        "    \n",
        "    try:\n",
        "      if (e['entity_group'] == \"SPECIES\" or e['entity_group'] == \"HUMAN\") and (e['start'] == (output[-2]['end']+1)) and (e['entity_group'] == output[-2]['entity_group']):\n",
        "        output[-2]['word'] = output[-2]['word']+\" \"+e['word']\n",
        "        output[-2]['end'] = e['end']\n",
        "        output.pop(-1)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    try:\n",
        "      if e['start'] == (output[-2]['end']):\n",
        "        output[-2]['word'] = output[-2]['word']+e['word']\n",
        "        output[-2]['end'] = e['end']\n",
        "        output.pop(-1)\n",
        "    except:\n",
        "      pass\n",
        "    \n",
        "\n",
        "  return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hPi30NgqtDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f5b6a4-5aad-48fc-fd21-0fdab6af59ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'HUMAN',\n",
              "  'score': 0.9996307,\n",
              "  'word': 'Paciente',\n",
              "  'start': 3,\n",
              "  'end': 11}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "grouping_entities(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZwOFHailsVL"
      },
      "source": [
        "## Predictions on test datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "test_files = os.listdir(test_path)"
      ],
      "metadata": {
        "id": "OUZsJuIdQcOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Processing...\")\n",
        "import re\n",
        "f = open(\"/content/drive/MyDrive/Results/test_predictions_mBERT_ParTNER-1.tsv\", \"w\", encoding=\"UTF-8\")\n",
        "\n",
        "f.write(\"filename\\tmark\\tlabel\\toff0\\toff1\\tspan\\n\")\n",
        "\n",
        "for fl in test_files:\n",
        "  with open(test_path +'/'+ fl, \"r\", encoding=\"UTF-8\") as ftest:\n",
        "    lista_spans = []\n",
        "    hc = ftest.read()\n",
        "    #Partitioning the texts.\n",
        "    t = 1\n",
        "    pattern = r'\\. |\\.\\n|\\. \\n'\n",
        "    sents = re.split(pattern, hc)\n",
        "\n",
        "    paragraphs = []\n",
        "    prgh = \"\"\n",
        "\n",
        "    #Paragraphs with 'step or pl' sentences no overlapping\n",
        "    ant = 0\n",
        "    step = 1\n",
        "    pl = 1 #paragraph length\n",
        "    for lpr in range(pl,len(sents),step):\n",
        "      paragraphs.append(\" \".join(sents[ant:lpr]))  \n",
        "      ant = lpr\n",
        "    if lpr != len(sents):\n",
        "      paragraphs.append(\" \".join(sents[lpr:]))\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    #Paragraphs with 1-sentence window\n",
        "    ant = 0\n",
        "    step = 3\n",
        "    pl = 5 #paragraph length\n",
        "    for lpr in range(pl,len(sents),step):\n",
        "      paragraphs.append(\" \".join(sents[ant:lpr]))  \n",
        "      ant+=step\n",
        "    '''\n",
        "  \n",
        "    #Inference per paragraphs\n",
        "    for ph in paragraphs: \n",
        "\n",
        "      pred = token_classifier(ph)\n",
        "      pred_grouped = grouping_entities(pred)\n",
        "  \n",
        "      for p in pred_grouped:\n",
        "\n",
        "        off0 = int(p['start'])\n",
        "        off1 = int(p['end'])\n",
        "        if p['entity_group'] == 'SPECIES':\n",
        "          label = 'SPECIES'\n",
        "        else:\n",
        "          label = 'HUMAN'\n",
        "        #span = hc[off0:off1]\n",
        "        span = p['word'] #for mBERT\n",
        "\n",
        "        \n",
        "        span = re.sub(\"^, |^,|^\\. |^\\.|^: |^:|^; |^;|^\\( |^\\(|^\\) |^\\)\",\"\",span)\n",
        "\n",
        "        if \"\\n\" in span:\n",
        "          span = re.sub(\"\\n\",\" \",span)\n",
        "\n",
        "        if \" - \" in span:\n",
        "          span = re.sub(\" - \",\"-\",span)\n",
        "\n",
        "        if \"- \" in span:\n",
        "          span = re.sub(\"- \",\"-\",span)\n",
        "\n",
        "        if \" -\" in span:\n",
        "          span = re.sub(\" -\",\"-\",span)\n",
        "\n",
        "        if \"( \" in span:\n",
        "          span = re.sub(\"\\( \",\"(\",span)\n",
        "\n",
        "        if \" )\" in span:\n",
        "          span = re.sub(\" \\)\",\")\",span)\n",
        "\n",
        "        if span.endswith(\" y\") :\n",
        "          span = span[:-2]\n",
        "\n",
        "        if span.endswith(\" de\") or span.endswith(\" en\"):\n",
        "          span = span[:-3]\n",
        "\n",
        "        if span.endswith(\" por\") or span.endswith(\" con\"):\n",
        "          span = span[:-4]\n",
        "\n",
        "        if span.endswith(\".\") or span.endswith(\",\") or span.endswith(\";\") or span.endswith(\":\") or span.endswith(\"–\") or span.endswith(\"-\"):\n",
        "          span = span[:-1]\n",
        "\n",
        "        if span.endswith(\" .\") or span.endswith(\" ,\") or span.endswith(\" ;\") or span.endswith(\" :\") or span.endswith(\" –\") or span.endswith(\" -\"):\n",
        "          span = span[:-2]\n",
        "\n",
        "        #if span in [\"\",\".\", \",\", \";\", \":\", '\"', \"-\", \"a\", \"de\", \"por\", \"in\", \"que\", \"da\", \"di\", \"se\", \"Las\", \"re\", \"sin\", \"en\", \"(\", \")\", \"la\", \"y\", \"con\", \"o\", \"E\", \"ba\", \"mic\", \"su\", \"no\", \"S\", \"sa\", \"P\", \"co\"] or span in Calphabet or span in alphabet or span in numbers:\n",
        "          #continue\n",
        "\n",
        "        pattern = r\"^[a-z|á|é|í|ó|ú|/]{0,3}$|^[0-9]+$|^[A-Z]$\"\n",
        "        match = re.findall(pattern, span)\n",
        "        if len(match) > 0 and match[0] != 'tía' and match[0] != 'tío':\n",
        "          continue\n",
        "\n",
        "        if span not in lista_spans:\n",
        "          # Find all indices of 'span'\n",
        "          indices = [index for index in range(len(hc)) if hc.startswith(span, index)]\n",
        "          #print(indices)\n",
        "          for ind in indices:\n",
        "            off0 = ind\n",
        "            off1 = ind+len(span)\n",
        "            f.write(fl[:-4]+\"\\t\"+\"T\"+str(t)+\"\\t\"+label+\"\\t\"+str(off0)+\"\\t\"+str(off1)+\"\\t\"+span+\"\\n\")\n",
        "            #print(filename[:-4]+\"\\t\"+\"T\"+str(t)+\"\\t\"+label+\"\\t\"+str(off0)+\"\\t\"+str(off1)+\"\\t\"+span+\"\\n\")\n",
        "            t+=1\n",
        "\n",
        "          lista_spans.append(span)\n",
        "f.close()\n",
        "print(\"Completo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeTXGqyI5M42",
        "outputId": "a351672f-a22a-4e03-8d16-d97ae9e33e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing...\n",
            "Completo.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a7a1206483c943629eb275efad778604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcceebadf1a84506851de9be3bb5f445",
              "IPY_MODEL_240505ccac0b4df195714a05c8cbf76e",
              "IPY_MODEL_aedbd116a0c440dcaad1b27538bee22d"
            ],
            "layout": "IPY_MODEL_03390e8efc104ce1bb02369466aa5432"
          }
        },
        "bcceebadf1a84506851de9be3bb5f445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2308e9e1f5224b24bd474d09d51cabb2",
            "placeholder": "​",
            "style": "IPY_MODEL_8f546f8e42d54b688bc2fe0f1878a94d",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "240505ccac0b4df195714a05c8cbf76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_068447f162754e13b1158e18f97b2f0d",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91956b73060b48c6a95513373d7eac15",
            "value": 714314041
          }
        },
        "aedbd116a0c440dcaad1b27538bee22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb52128e47694a8eab6fb71b8dd8ac5d",
            "placeholder": "​",
            "style": "IPY_MODEL_1b65950e82f841bca67f66cf15f9247f",
            "value": " 714M/714M [00:05&lt;00:00, 145MB/s]"
          }
        },
        "03390e8efc104ce1bb02369466aa5432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2308e9e1f5224b24bd474d09d51cabb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f546f8e42d54b688bc2fe0f1878a94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "068447f162754e13b1158e18f97b2f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91956b73060b48c6a95513373d7eac15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb52128e47694a8eab6fb71b8dd8ac5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b65950e82f841bca67f66cf15f9247f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}